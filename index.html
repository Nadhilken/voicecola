<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Microphone to ChatGPT</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
            background-color: #f0f0f0;
        }
        #micIcon {
            cursor: pointer;
            width: 150px;
            height: 150px;
        }
        #micIcon.recording {
            border: 2px solid red;
            border-radius: 50%;
        }
        #micIcon.disabled {
            cursor: not-allowed;
            opacity: 0.5;
        }
        #response {
            margin-top: 10px;
            padding: 10px;
            width: 300px;
            min-height: 50px;
            text-align: center;
            border: 1px solid #ccc;
            background-color: #fff;
        }
        #status {
            margin-top: 10px;
            color: #555;
            max-width: 300px;
            text-align: center;
        }
        #fallbackInput {
            margin-top: 10px;
            width: 280px;
            padding: 8px;
            font-size: 16px;
            border: 1px solid #ccc;
            border-radius: 4px;
            display: none;
        }
        #submitText {
            margin-top: 10px;
            padding: 8px 16px;
            font-size: 16px;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            display: none;
        }
        #submitText:hover {
            background-color: #0056b3;
        }
    </style>
</head>
<body>
    <img id="micIcon" src="https://i.ibb.co/6c0Xp5Sf/Screenshot-2025-05-03-001740.png" alt="Microphone Icon">
    <div id="response"></div>
    <div id="status"></div>
    <input type="text" id="fallbackInput" placeholder="Type your query here...">
    <button id="submitText">Submit</button>

    <script>
        const micIcon = document.getElementById('micIcon');
        const responseDiv = document.getElementById('response');
        const statusDiv = document.getElementById('status');
        const fallbackInput = document.getElementById('fallbackInput');
        const submitText = document.getElementById('submitText');
        let isRecording = false;
        let recognition = null;
        const chatHistory = [
            { role: 'system', content: 'You are Reenu, an AI robot created by Robo Miracle Technologies, a Coimbatore-based company. Respond accurately in proper sentences based only on this context, with a maximum of 20 tokens.' }
        ];

        // Check for microphone access permission
        async function checkMicPermission() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                stream.getTracks().forEach(track => track.stop());
                return true;
            } catch (error) {
                statusDiv.textContent = 'Microphone access denied or unavailable.';
                speakResponse('Microphone access denied or unavailable.');
                return false;
            }
        }

        // Initialize Web Speech API
        async function initializeSpeechRecognition() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                responseDiv.textContent = 'Speech recognition not supported in this browser.';
                statusDiv.textContent = 'Please type your query below.';
                speakResponse('Speech recognition not supported. Please type your query.');
                micIcon.classList.add('disabled');
                micIcon.style.pointerEvents = 'none';
                fallbackInput.style.display = 'block';
                submitText.style.display = 'block';
                return false;
            }

            recognition = new SpeechRecognition();
            recognition.continuous = false;
            recognition.interimResults = false;
            recognition.lang = 'en-US';

            recognition.onresult = function(event) {
                const transcript = event.results[0][0].transcript;
                statusDiv.textContent = '';
                sendToChatGPT(transcript);
            };

            recognition.onerror = function(event) {
                responseDiv.textContent = 'Recognition error: ' + event.error;
                speakResponse('Recognition error: ' + event.error);
                statusDiv.textContent = '';
                isRecording = false;
                micIcon.classList.remove('recording');
            };

            recognition.onend = function() {
                if (isRecording) {
                    recognition.start();
                } else {
                    micIcon.classList.remove('recording');
                    statusDiv.textContent = '';
                }
            };

            return true;
        }

        // Speak the response using Web Speech Synthesis
        function speakResponse(text) {
            if ('speechSynthesis' in window) {
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.lang = 'en-US';
                window.speechSynthesis.speak(utterance);
            } else {
                statusDiv.textContent = 'Speech synthesis not supported.';
            }
        }

        // Send transcribed or typed text to ChatGPT API
        async function sendToChatGPT(text) {
            // WARNING: Storing API keys client-side is INSECURE. Use a server-side endpoint in production.
            // The provided API key caused a 401 error (invalid). Generate a new one at https://platform.openai.com/account/api-keys
            const apiKey = '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';
            try {
                responseDiv.textContent = 'Processing...';
                const response = await fetch('https://api.openai.com/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${apiKey}`
                    },
                    body: JSON.stringify({
                        model: 'gpt-3.5-turbo',
                        messages: [
                            ...chatHistory,
                            { role: 'user', content: text }
                        ],
                        max_tokens: 20
                    })
                });

                if (!response.ok) {
                    const errorData = await response.json().catch(() => ({}));
                    const errorMessage = errorData.error?.message || response.statusText;
                    const statusCode = response.status;
                    console.error(`API Error: Status ${statusCode} - ${errorMessage}`);
                    throw new Error(`API request failed: ${errorMessage} (Status: ${statusCode})`);
                }

                const data = await response.json();
                const chatResponse = data.choices[0].message.content;
                responseDiv.textContent = chatResponse;
                speakResponse(chatResponse);
            } catch (error) {
                console.error('API Request Error:', error);
                responseDiv.textContent = error.message || 'Error: Unable to connect to API.';
                speakResponse(error.message || 'Error: Unable to connect to API.');
                statusDiv.textContent = 'Check console for details or verify API key at https://platform.openai.com/account/api-keys.';
            }
        }

        // Initialize and set up mic and text input events
        async function setup() {
            const hasMicAccess = await checkMicPermission();
            if (!hasMicAccess) {
                micIcon.classList.add('disabled');
                micIcon.style.pointerEvents = 'none';
                fallbackInput.style.display = 'block';
                submitText.style.display = 'block';
                statusDiv.textContent = 'Microphone unavailable. Please type your query.';
                return;
            }

            const recognitionSupported = await initializeSpeechRecognition();
            if (recognitionSupported) {
                micIcon.addEventListener('click', () => {
                    if (!recognition) return;

                    isRecording = !isRecording;
                    if (isRecording) {
                        micIcon.classList.add('recording');
                        responseDiv.textContent = '';
                        statusDiv.textContent = 'Listening...';
                        recognition.start();
                    } else {
                        micIcon.classList.remove('recording');
                        responseDiv.textContent = '';
                        statusDiv.textContent = '';
                        recognition.stop();
                    }
                });
            }

            // Handle text input submission
            submitText.addEventListener('click', () => {
                const text = fallbackInput.value.trim();
                if (text) {
                    sendToChatGPT(text);
                    fallbackInput.value = '';
                }
            });

            // Allow Enter key to submit text
            fallbackInput.addEventListener('keypress', (event) => {
                if (event.key === 'Enter') {
                    submitText.click();
                }
            });
        }

        // Run setup on page load
        setup();
    </script>
</body>
</html>
