<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Microphone to Gemini</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
            background-color: #f0f0f0;
        }
        #micIcon {
            cursor: pointer;
            width: 150px;
            height: 150px;
        }
        #micIcon.recording {
            border: 2px solid red;
            border-radius: 50%;
        }
        #response {
            margin-top: 10px;
            padding: 10px;
            width: 300px;
            min-height: 50px;
            text-align: center;
        }
    </style>
</head>
<body>
    <img id="micIcon" src="https://i.ibb.co/6c0Xp5Sf/Screenshot-2025-05-03-001740.png" alt="Microphone Icon">
    <div id="response"></div>

    <script>
        const micIcon = document.getElementById('micIcon');
        const responseDiv = document.getElementById('response');
        let isRecording = false;
        let recognition;
        const chatHistory = [
            { role: 'system', content: 'You are Reenu, an AI robot created by Robo Miracle Technologies, a Coimbatore-based company. Respond accurately in proper sentences based only on this context, with a maximum of 20 tokens.' }
        ];

        // Check if Web Speech API is available
        if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
            recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
            recognition.continuous = false;
            recognition.interimResults = false;
            recognition.lang = 'en-US';

            recognition.onresult = function(event) {
                const transcript = event.results[0][0].transcript;
                sendToGemini(transcript);
            };

            recognition.onerror = function(event) {
                responseDiv.textContent = 'Error in recognition: ' + event.error;
                speakResponse('Error in recognition: ' + event.error);
            };

            recognition.onend = function() {
                if (isRecording && !window.speechSynthesis.speaking) {
                    recognition.start();
                }
            };
        } else {
            responseDiv.textContent = 'Speech recognition not supported.';
            speakResponse('Speech recognition not supported.');
        }

        // Toggle recording on icon click
        micIcon.addEventListener('click', () => {
            if (!recognition) return;

            isRecording = !isRecording;
            if (isRecording && !window.speechSynthesis.speaking) {
                micIcon.classList.add('recording');
                responseDiv.textContent = 'Listening...';
                recognition.start();
            } else {
                micIcon.classList.remove('recording');
                responseDiv.textContent = '';
                recognition.stop();
            }
        });

        // Speak the response using Web Speech Synthesis
        function speakResponse(text) {
            if (isRecording) {
                recognition.stop();
                isRecording = false;
                micIcon.classList.remove('recording');
            }
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = 'en-US';
            utterance.onend = function() {
                if (isRecording && !window.speechSynthesis.speaking) {
                    recognition.start();
                    micIcon.classList.add('recording');
                    responseDiv.textContent = 'Listening...';
                }
            };
            window.speechSynthesis.speak(utterance);
        }

        // Send transcribed text to Gemini API
        async function sendToGemini(text) {
            const apiKey = 'AIzaSyCux4a3RKAz_KByWpJ7-IcKuAC21KQuoU0';
            try {
                const response = await fetch('https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'x-goog-api-key': apiKey
                    },
                    body: JSON.stringify({
                        contents: [
                            {
                                parts: [
                                    { text: chatHistory[0].content },
                                    { text: text }
                                ]
                            }
                        ],
                        generationConfig: {
                            maxOutputTokens: 20
                        }
                    })
                });

                if (!response.ok) {
                    throw new Error('API request failed: ' + response.statusText);
                }

                const data = await response.json();
                const geminiResponse = data.candidates[0].content.parts[0].text;
                responseDiv.textContent = geminiResponse;
                speakResponse(geminiResponse);
            } catch (error) {
                responseDiv.textContent = 'Error: ' + error.message;
                speakResponse('Error: ' + error.message);
            }
        }
    </script>
</body>
</html>
